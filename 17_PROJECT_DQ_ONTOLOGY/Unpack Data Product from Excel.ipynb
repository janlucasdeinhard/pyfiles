{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports\n",
    "\n",
    "import numpy as np\n",
    "from numpy import random as rnd\n",
    "from matplotlib import pyplot as plt\n",
    "import os,sys,datetime,time,math, warnings,itertools\n",
    "\n",
    "import pandas as pd\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# Snowpark imports\n",
    "from snowflake.snowpark.session import Session\n",
    "import snowflake.snowpark.functions as F\n",
    "import snowflake.snowpark.types as T\n",
    "from snowflake.snowpark.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_single_lineage_extract(excel_path):\n",
    "    \"\"\"\n",
    "    Read and process an Informatica Lineage Excel extract for a single lineage.\n",
    "\n",
    "    This function reads an Informatica Lineage Excel extract file, performs post-processing\n",
    "    specific to this file type, and returns a DataFrame containing relevant lineage information.\n",
    "\n",
    "    Args:\n",
    "        excel_path (str): The file path to the Informatica Lineage Excel extract.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing lineage information with the following columns:\n",
    "            - 'Accounts'\n",
    "            - 'Martlayer.CRMCLOUD_OSC.Accounts'\n",
    "            - 'SF_CRM_DataMarts/MARTLAYER/CRMCLOUD_OSC/Accounts/'\n",
    "            - 'Source File'\n",
    "\n",
    "    Note:\n",
    "        The function expects the input Excel file to have a specific structure as defined by Informatica Lineage.\n",
    "        The function will skip the first two rows and use the third row as the header row for reading the DataFrame.\n",
    "        Post-processing is applied to filter the DataFrame based on the 'SF_CRM_DataMarts' column and select specific\n",
    "        columns related to the 'Accounts' lineage. The 'Source File' column will be added to the DataFrame with the value\n",
    "        of the 'excel_path' argument.\n",
    "\n",
    "    Example:\n",
    "        excel_path = 'path/to/lineage_extract.xlsx'\n",
    "        lineage_df = read_single_lineage_extract(excel_path)\n",
    "    \"\"\"\n",
    "    # Expects file structure as defined by Informatica Lineage output\n",
    "    df = pd.read_excel(excel_path,skiprows=2,header=1)\n",
    "    # Postprocessing defined for this specific file type\n",
    "    df = df[df['Resource Name']=='SF_CRM_DataMarts'].filter(items=[\n",
    "        'Asset Name',\n",
    "        'Business_Terms',\n",
    "        'Path'\n",
    "    ],axis=1)\n",
    "    df['DP Table'] = excel_path.replace('.xls','').replace('.xlsx','')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def cwd(path):\n",
    "    \"\"\"\n",
    "    Context manager to temporarily change the current working directory.\n",
    "\n",
    "    This context manager changes the current working directory to the specified 'path'\n",
    "    while the context is active. After the context exits, the original working directory\n",
    "    is restored.\n",
    "\n",
    "    Args:\n",
    "        path (str): The path to the directory to which the current working directory should be changed.\n",
    "\n",
    "    Usage:\n",
    "        with cwd('/path/to/new/directory'):\n",
    "            # Code executed within this block will have the current working directory changed.\n",
    "            # After the block exits, the original working directory is restored.\n",
    "\n",
    "    Example:\n",
    "        with cwd('/home/user/documents'):\n",
    "            file_list = os.listdir()  # List files in the '/home/user/documents' directory\n",
    "        # \n",
    "    \"\"\"\n",
    "    oldpwd = os.getcwd()\n",
    "    os.chdir(path)\n",
    "    try: yield\n",
    "    finally: os.chdir(oldpwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path settings\n",
    "if sys.platform.startswith('win'):\n",
    "    excel_input_directory = r'../../TF_Data/Dropbox/PhD Prep/DQ Framework - Clustering/Data Products/Informatica Lineage Status Funnel Management 11.08.2023/'\n",
    "    excel_output_directory = r'../../TF_Data/Dropbox/PhD Prep/DQ Framework - Clustering/Data Products/'\n",
    "    shsdq_directory = r'../../TF_Data/Dropbox/PhD Prep/SHS DQ/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Excel files to construct columns in data product\n",
    "with cwd(excel_input_directory):\n",
    "    df = pd.DataFrame()\n",
    "    # Iterate tables in Data Product\n",
    "    for dp_member in os.listdir():\n",
    "        df = pd.concat([df,read_single_lineage_extract(dp_member)],axis=0)\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "# Post-processing\n",
    "df['Path_tmp'] = df['Path'].str.split('/')\n",
    "df[['TABLE_CATALOG','TABLE_SCHEMA','TABLE_NAME']] = pd.DataFrame(df.Path_tmp.tolist(),index=df.index).drop(columns=[0,4])\n",
    "df = df.drop(columns=['Path_tmp','Path'])\n",
    "df['TABLE_PATH'] = df[['TABLE_CATALOG','TABLE_SCHEMA','TABLE_NAME']].apply(lambda x: '\\\"'+x[0]+'\\\".\\\"'+x[1]+'\\\".\\\"'+x[2]+'\\\"',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine centrality of each Martlayer table\n",
    "ddf = df.groupby(['TABLE_PATH'],as_index=False)['DP Table'].nunique().assign(\n",
    "    new=df['DP Table'].nunique()\n",
    ").rename(\n",
    "    columns={\n",
    "        'DP Table':'DP Tables using TABLE',\n",
    "        'new':'Total DP Tables'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Calculate Centrality Factor\n",
    "ddf['Centrality Factor'] = ddf[['DP Tables using TABLE','Total DP Tables']].apply(lambda x: x[0]/x[1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection Parameters\n",
    "connection_parameters = {\n",
    "    'account':'shsitdl.west-europe.azure',\n",
    "    'user':'jan-lucas.deinhard@siemens-healthineers.com',\n",
    "    'authenticator':'externalbrowser',\n",
    "    'role':'FR_CRMCLOUD_DEV',\n",
    "    'database':'MARTLAYER',\n",
    "    'schema':'INFORMATION_SCHEMA',\n",
    "    'warehouse':'W_CRMCLOUD_P'\n",
    "}\n",
    "\n",
    "# Establish Connection\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "\n",
    "cC = session.table(\"COLUMNS\")\n",
    "C = pd.DataFrame(cC.collect())\n",
    "\n",
    "session.close()\n",
    "\n",
    "# Merge all columns into the DP-relevant tables\n",
    "dq = df.merge(\n",
    "    C[['TABLE_CATALOG','TABLE_SCHEMA','TABLE_NAME','COLUMN_NAME']].drop_duplicates(),\n",
    "    on=['TABLE_CATALOG','TABLE_SCHEMA','TABLE_NAME'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DQ Flags file\n",
    "with cwd(shsdq_directory):\n",
    "    dqf = pd.read_excel('DQ Flags in CDC.xlsx')\n",
    "# Filter the columns to the DQ Flags\n",
    "dq = dq.merge(dqf[['Name']].drop_duplicates().rename(columns={'Name':'COLUMN_NAME'}),on='COLUMN_NAME',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write result to Excel file\n",
    "with cwd(excel_output_directory), pd.ExcelWriter('Funnel Management Data Product.xlsx') as writer:\n",
    "    df.to_excel(writer, sheet_name='Data Assets per Data Product',index=False)\n",
    "    ddf.to_excel(writer, sheet_name='Relevance per Data Asset',index=False)\n",
    "    dq.to_excel(writer, sheet_name='DQ Flags per Data Product',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
